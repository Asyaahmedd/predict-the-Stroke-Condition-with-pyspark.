{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The objective from this project is to create a <b>Logistic Regression Classifier</b> to predict the <b>Stroke Condition</b>.\n",
    "- <b>Stoke</b> is a condition in which either the blood flow to the brain stops or blood flow is excessive.\n",
    "- It is required to obtain <b>ROC > 0.65</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "- Data is provided in csv format in a file named <b>healthcare-dataset-stroke-data.csv</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names and data types are as follow:\n",
    "- id, integer.\n",
    "- gender, string.\n",
    "- age, double.\n",
    "- hypertension, integer.\n",
    "- heart_disease, integer.\n",
    "- ever_married, string.\n",
    "- work_type, string.\n",
    "- Residence_type, string.\n",
    "- avg_glucose_level, double.\n",
    "- bmi, double.\n",
    "- smoking_status, string.\n",
    "- stroke, integer <b>(Target Label)</b>.\n",
    "If the person has stroke the stroke label value is <b>\"1\"</b> otherwise <b>\"0\"</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "spark = (SparkSession\n",
    ".builder\n",
    ".appName(\"Finalexam\")\n",
    ".getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Create a data schema programatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = StructType([StructField(\"id\", IntegerType(), False),\n",
    "                     StructField(\"gender\", StringType(), False),\n",
    "                     StructField(\"age\", DoubleType(), False),\n",
    "                     StructField(\"hypertension\", IntegerType(), False),\n",
    "                     StructField(\"heart_disease\", IntegerType(), False),\n",
    "                     StructField(\"ever_married\", StringType(), False),\n",
    "                     StructField(\"work_type\", StringType(), False),\n",
    "                     StructField(\"Residence_type\", StringType(), False),\n",
    "                     StructField(\"avg_glucose_level\", DoubleType(), False),\n",
    "                     StructField(\"bmi\", DoubleType(), False),\n",
    "                     StructField(\"smoking_status\", StringType(), False),\n",
    "                     StructField(\"stroke\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Read the data using the standard DataReader (Key,Value) pairs format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.csv('/home/asya/Downloads/healthcare-dataset-stroke-data.csv',schema=data_schema ,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Explore the data \n",
    "\n",
    "- Print the Schema.\n",
    "- Show the first 10 rows from the data.\n",
    "- Explore null values and show how many null values in each column.\n",
    "- Plot a count plot for the target label and <b>notice the graph</b>.\n",
    "- Perform any additional EDA you find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n",
      "|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21|null|   never smoked|     1|\n",
      "|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n",
      "|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n",
      "| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|24.0|   never smoked|     1|\n",
      "|56669|  Male|81.0|           0|            0|         Yes|      Private|         Urban|           186.21|29.0|formerly smoked|     1|\n",
      "|53882|  Male|74.0|           1|            1|         Yes|      Private|         Rural|            70.09|27.4|   never smoked|     1|\n",
      "|10434|Female|69.0|           0|            0|          No|      Private|         Urban|            94.39|22.8|   never smoked|     1|\n",
      "|27419|Female|59.0|           0|            0|         Yes|      Private|         Rural|            76.15|null|        Unknown|     1|\n",
      "|60491|Female|78.0|           0|            0|         Yes|      Private|         Urban|            58.57|24.2|        Unknown|     1|\n",
      "+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "| id|gender|age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|bmi|smoking_status|stroke|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "|  0|     0|  0|           0|            0|           0|        0|             0|                0|201|             0|     0|\n",
      "+---+------+---+------------+-------------+------------+---------+--------------+-----------------+---+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "count_null_df = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "count_null_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stroke', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pandasDF = df.toPandas()\n",
    "print(len(pandasDF))\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='stroke', data=pandasDF, order=pandasDF['stroke'].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the summary statistics of the age column\n",
    "- the minimum age is about <b>0.08</b>.\n",
    "- Remove rows for the age below <b>2 years old</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|              5110|\n",
      "|   mean|43.226614481409015|\n",
      "| stddev| 22.61264672311348|\n",
      "|    min|              0.08|\n",
      "|    max|              82.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\").summary(\"count\",\"mean\",\"stddev\",\"min\",\"max\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(\"age > 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with gender & smoking_status columns:\n",
    "- Select and show the gender & smoking_status columns\n",
    "- Get the distinct values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|gender| smoking_status|\n",
      "+------+---------------+\n",
      "|  Male|formerly smoked|\n",
      "|Female|   never smoked|\n",
      "|  Male|   never smoked|\n",
      "|Female|         smokes|\n",
      "|Female|   never smoked|\n",
      "|  Male|formerly smoked|\n",
      "|  Male|   never smoked|\n",
      "|Female|   never smoked|\n",
      "|Female|        Unknown|\n",
      "|Female|        Unknown|\n",
      "|Female|   never smoked|\n",
      "|Female|         smokes|\n",
      "|Female|         smokes|\n",
      "|  Male|        Unknown|\n",
      "|Female|   never smoked|\n",
      "|Female|   never smoked|\n",
      "|  Male|         smokes|\n",
      "|  Male|         smokes|\n",
      "|Female|   never smoked|\n",
      "|  Male|        Unknown|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('gender','smoking_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|Female|\n",
      "| Other|\n",
      "|  Male|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('gender').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "| smoking_status|\n",
      "+---------------+\n",
      "|         smokes|\n",
      "|        Unknown|\n",
      "|   never smoked|\n",
      "|formerly smoked|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('smoking_status').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQFPKukRLzbB"
   },
   "source": [
    "#### Changing the string values of the columns into numerical values as follow:\n",
    "1. Gender column:\n",
    "    * Male = 1 \n",
    "    * Female = 0 \n",
    "    * Other = 0 \n",
    "2. Smoking Status column:\n",
    "  * never smoked = 0\n",
    "  * Unknown = 0.5\n",
    "  * formerly smoked = 0.75\n",
    "  * smokes = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_gender(val):\n",
    "    if val =='Male':\n",
    "        return 1\n",
    "    elif val == 'Female':\n",
    "        return 0\n",
    "    elif val == 'Other':\n",
    "        return 0\n",
    "def mapping_smoking(val):\n",
    "    if val =='never smoked':\n",
    "        return 0.0\n",
    "    elif val == 'Unknown':\n",
    "        return 0.5\n",
    "    elif val == 'formerly smoked':\n",
    "        return 0.75\n",
    "    elif val == 'smokes':\n",
    "        return 1.0  \n",
    "\n",
    "mapping_genderUDF = udf(lambda z: mapping_gender(z))\n",
    "mapping_smokingUDF = udf(lambda z: mapping_smoking(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = filtered_df.withColumn(\"gender_mapped\", mapping_genderUDF(col(\"gender\")))\n",
    "filtered_df = temp.withColumn(\"smoking_status_mapped\", mapping_smokingUDF(col(\"smoking_status\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = filtered_df.drop('gender','smoking_status')\n",
    "temp = temp.withColumnRenamed('smoking_status_mapped','smoking_status')\n",
    "filtered_df = temp.withColumnRenamed('gender_mapped','gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the output DataFrame\n",
    "- Select and show the gender & smoking_status columns after value changing.\n",
    "- Print schema for the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|gender|smoking_status|\n",
      "+------+--------------+\n",
      "|     1|          0.75|\n",
      "|     0|           0.0|\n",
      "|     1|           0.0|\n",
      "|     0|           1.0|\n",
      "|     0|           0.0|\n",
      "|     1|          0.75|\n",
      "|     1|           0.0|\n",
      "|     0|           0.0|\n",
      "|     0|           0.5|\n",
      "|     0|           0.5|\n",
      "|     0|           0.0|\n",
      "|     0|           1.0|\n",
      "|     0|           1.0|\n",
      "|     1|           0.5|\n",
      "|     0|           0.0|\n",
      "|     0|           0.0|\n",
      "|     1|           1.0|\n",
      "|     1|           1.0|\n",
      "|     0|           0.0|\n",
      "|     1|           0.5|\n",
      "+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('gender','smoking_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('gender').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|smoking_status|\n",
      "+--------------+\n",
      "|           1.0|\n",
      "|          0.75|\n",
      "|           0.0|\n",
      "|           0.5|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.select('smoking_status').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with null value according to your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.257489451476793\n"
     ]
    }
   ],
   "source": [
    "fill_values =  filtered_df.agg({'bmi':\"mean\"}).collect()[0][0]\n",
    "print(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df = filtered_df.bmi.na.fill(fill_values)\n",
    "filtered_df = filtered_df.fillna({'bmi':fill_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = false)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------+-------------+------------+---------+--------------+-----------------+---+------+------+--------------+\n",
      "| id|age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|bmi|stroke|gender|smoking_status|\n",
      "+---+---+------------+-------------+------------+---------+--------------+-----------------+---+------+------+--------------+\n",
      "|  0|  0|           0|            0|           0|        0|             0|                0|  0|     0|     0|             0|\n",
      "+---+---+------------+-------------+------------+---------+--------------+-----------------+---+------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make sure that all nulls are imputed\n",
    "\n",
    "count_null_df = filtered_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in filtered_df.columns])\n",
    "count_null_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test dataframes:\n",
    "- 80% training and 20% test.\n",
    "- seed = 42.\n",
    "- Save each dataframe as a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3991 rows in the training set, and 944 in the test set\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = filtered_df.randomSplit([.8,.2],seed=42)\n",
    "print(f\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainDF.write.format(\"parquet\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"compression\", \"snappy\")\n",
    " .save(\"train_df_parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(testDF.write.format(\"parquet\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"compression\", \"snappy\")\n",
    " .save(\"test_df_parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the saved Train and Test DataFrame:\n",
    "- Use the dataframes I read in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.format('parquet').load('train_df_parquet')\n",
    "test_df = spark.read.format('parquet').load('test_df_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------------+-------------+------------+---------+--------------+-----------------+------------------+------+------+--------------+\n",
      "| id| age|hypertension|heart_disease|ever_married|work_type|Residence_type|avg_glucose_level|               bmi|stroke|gender|smoking_status|\n",
      "+---+----+------------+-------------+------------+---------+--------------+-----------------+------------------+------+------+--------------+\n",
      "| 67|17.0|           0|            0|          No|  Private|         Urban|            92.97|29.257489451476793|     0|     0|          0.75|\n",
      "| 77|13.0|           0|            0|          No| children|         Rural|            85.81|              18.6|     0|     0|           0.5|\n",
      "+---+----+------------+-------------+------------+---------+--------------+-----------------+------------------+------+------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model:\n",
    "- Perform feature engineering steps.\n",
    "- Create the logistic regression classifier.\n",
    "- Build the pipeline model that uses all feature engineering steps and the model.\n",
    "- Train the pipeline model using the trainig dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn(\"smoking_status\", train_df[\"smoking_status\"].cast(\"double\"))\n",
    "test_df = test_df.withColumn(\"smoking_status\", test_df[\"smoking_status\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop('id')\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop('id')\n",
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married', 'work_type', 'Residence_type', 'gender']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "categoricalCols = [field for (field, dataType) in train_df.dtypes\n",
    "                   if dataType == \"string\"]\n",
    "\n",
    "categoricalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_Index',\n",
       " 'work_type_Index',\n",
       " 'Residence_type_Index',\n",
       " 'gender_Index']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
    "indexOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_OHE', 'work_type_OHE', 'Residence_type_OHE', 'gender_OHE']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]\n",
    "oheOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "                             outputCols=indexOutputCols,\n",
    "                             handleInvalid='skip')\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                          outputCols=oheOutputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericCols = [field for (field,dataType) in trainDF.dtypes\n",
    "              if ((dataType=='double' or dataType=='int' )and (field!=\"stroke\" and field!=\"id\"))]\n",
    "numericCols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever_married_OHE',\n",
       " 'work_type_OHE',\n",
       " 'Residence_type_OHE',\n",
       " 'gender_OHE',\n",
       " 'age',\n",
       " 'hypertension',\n",
       " 'heart_disease',\n",
       " 'avg_glucose_level',\n",
       " 'bmi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = oheOutputCols + numericCols\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "  inputCols=assemblerInputs,\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features',labelCol=\"stroke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,lr])\n",
    "pipelineModel = pipeline.fit(train_df)\n",
    "predDF = pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform predictions on tests dataframe:\n",
    "- Test the model using the test dataframe\n",
    "- Select and show the feature column.\n",
    "- Print the schema of the output dataframe.\n",
    "- Select and show both prediction and label columns.\n",
    "- Explore the results for the label column stroke=1. i.e. select both columns (prediction,stroke) for stroke=1.<b>notice the result.</b> \n",
    "- Count the predicted 1 and 0 values.<b>notice the result.</b>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "|       0.0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(12,[0,1,5,7,10,1...|\n",
      "|(12,[1,5,6,7,10,1...|\n",
      "|(12,[0,1,6,7,10,1...|\n",
      "|(12,[0,1,6,7,10,1...|\n",
      "|(12,[0,1,5,7,10,1...|\n",
      "|(12,[0,1,6,7,10,1...|\n",
      "|(12,[0,2,7,8,10,1...|\n",
      "|[1.0,0.0,1.0,0.0,...|\n",
      "|(12,[4,6,7,10,11]...|\n",
      "|(12,[0,1,7,10,11]...|\n",
      "|(12,[0,3,7,10,11]...|\n",
      "|[0.0,1.0,0.0,0.0,...|\n",
      "|(12,[1,7,10,11],[...|\n",
      "|(12,[0,2,6,7,10,1...|\n",
      "|[1.0,1.0,0.0,0.0,...|\n",
      "|[1.0,0.0,0.0,1.0,...|\n",
      "|(12,[1,5,6,7,10,1...|\n",
      "|[1.0,1.0,0.0,0.0,...|\n",
      "|(12,[0,3,5,7,10,1...|\n",
      "|(12,[1,5,6,7,10,1...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      " |-- ever_married_Index: double (nullable = false)\n",
      " |-- work_type_Index: double (nullable = false)\n",
      " |-- Residence_type_Index: double (nullable = false)\n",
      " |-- gender_Index: double (nullable = false)\n",
      " |-- ever_married_OHE: vector (nullable = true)\n",
      " |-- work_type_OHE: vector (nullable = true)\n",
      " |-- Residence_type_OHE: vector (nullable = true)\n",
      " |-- gender_OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|stroke|\n",
      "+----------+------+\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     1|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     1|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "|       0.0|     0|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('prediction','stroke').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|stroke|prediction|\n",
      "+------+----------+\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('stroke','prediction').filter(predDF.stroke==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|stroke|prediction|\n",
      "+------+----------+\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "|     1|       0.0|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('stroke','prediction').filter(predDF.stroke==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|  943|\n",
      "|       1.0|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.groupBy('prediction').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model performance\n",
    "- Using <b>BinaryClassificationEvaluator</b>. This will calculate the <b>ROC</b>.\n",
    "- I Set the parameters as follow:\n",
    "    - <b>rawPredictionCol='prediction'</b> and <b>labelCol='stroke'</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorROC = BinaryClassificationEvaluator(rawPredictionCol='prediction'\n",
    "                                             ,labelCol='stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4994475138121547"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatorROC.evaluate(predDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Model Performance\n",
    "- I may noticed that <b>the target label is imbalanced</b>.\n",
    "- LogisticRegression classifier has a special parameter <b>weightCol</b> to deal with imbalanced class.\n",
    "- In order to use this parameter you must have a <b>weightCol</b> in your training dataframe.\n",
    "- In order to create this column you will need to define a <b>UDF</b> and apply it to the target label column.\n",
    "- Create a LogisticRegression classifier with <b>weightCol</b> parameter.\n",
    "- Build and train a pipeline model with the new LogisticRegression.\n",
    "- Perform the prediction on the test dataframe. \n",
    "- Select and show both prediction and label columns.\n",
    "- Explore the results for the label column stroke=1. i.e. select both columns (prediction,stroke) for stroke=1.<b>notice the result.</b> \n",
    "- Count the predicted 1 and 0 values.<b>notice the result.</b>   \n",
    "- Evaluate the model performance exactly as in the previous step.\n",
    "### I SHOULD OBTAIN  ROC > 0.65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(label):\n",
    "    if label == 1:\n",
    "        return 0.9551382368283776\n",
    "    else:\n",
    "        return 0.04486176317162238\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanceUDF = udf(lambda z: balance(z))\n",
    "temp = filtered_df.withColumn(\"gender_mapped\", mapping_genderUDF(col(\"gender\")))\n",
    "\n",
    "train_df = train_df.withColumn('weightCol',balanceUDF(col('stroke')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn(\"weightCol\", train_df[\"weightCol\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- smoking_status: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "colStringIndx = ['ever_married','work_type','Residence_type','gender']\n",
    "indexOutputCols = [x + \"_Index\" for x in colStringIndx]\n",
    "oheOutputCols = [x + \"_OHE\" for x in colStringIndx]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=colStringIndx,\n",
    "                             outputCols=indexOutputCols,\n",
    "                             handleInvalid='skip')\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                           outputCols = oheOutputCols)\n",
    "\n",
    "numericCols = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi','smoking_status']\n",
    "\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features',labelCol=\"stroke\",weightCol='weightCol')\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,lr])\n",
    "\n",
    "pipelineModelLR = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_W = pipelineModelLR.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593143504745715"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatorROC.evaluate(pred_W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
